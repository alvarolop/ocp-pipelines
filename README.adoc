= OpenShift Pipelines
Álvaro López Medina <alopezme@redhat.com>
v1.0, 2023-03
// Metadata
:description: This repository contains resources to deploy and test Openshift Pipelines
:keywords: openshift, pipelines, tekton, ci, red hat
// Create TOC wherever needed
:toc: macro
:sectanchors:
:sectnumlevels: 2
:sectnums: 
:source-highlighter: pygments
:imagesdir: images
// Start: Enable admonition icons
ifdef::env-github[]
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
ifndef::env-github[]
:icons: font
endif::[]

This repository contains resources to deploy and practice Openshift Pipelines.

// Create the Table of contents here
toc::[]

== Introduction

*Red Hat OpenShift Pipelines* is a cloud-native, continuous integration and continuous delivery (CI/CD) solution based on Kubernetes resources. It uses Tekton building blocks to automate deployments across multiple platforms by abstracting away the underlying implementation details. 

**What do we understand as Cloud Native CI/CD?**

* *Containers*: Built for container apps and runs on Kubernetes.
* *Serverless*: Runs serverless with no CI/CD engine to manage and maintain.
* *DevOps*: Designed with microservices and distributed teams in mind.


To get more details, you can check the https://docs.openshift.com/container-platform/4.12/cicd/pipelines/understanding-openshift-pipelines.html[official documentation].


== Installation of the operator

Installing the operator is as easy as creating a Subscription in the project `openshift-operators`. The Pipelines Operator is installed for All namespaces: 

[source, bash]
----
oc apply -f 00-installation/1-subscription.yaml
----

In order to split the pipelines executing from the operator itself, we will create another namespace where the pipelines will be executed:

[source, bash]
----
cat 00-installation/2-project-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 00-installation/2-project.yaml

oc apply -f 00-installation/2-project.yaml
----


== Useful Tasks for the pipelines

This section contains several tasks that can be useful for the pipelines. 


.*List files in the workspace*
[source, bash]
----
cat 10-tasks/1-list-files-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 10-tasks/1-list-files.yaml

oc apply -f 10-tasks/1-list-files.yaml
----





== Creating pipelines

.*Copy images from one repo to another*
[source, bash]
----
cat 20-pipelines/1-copy-images-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 20-pipelines/1-copy-images.yaml

oc apply -f 20-pipelines/1-copy-images.yaml
----

.*Bulk Copy images from one repo to another*
[source, bash]
----
cat 20-pipelines/2-copy-bulk-images-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 20-pipelines/2-copy-bulk-images.yaml

oc apply -f 20-pipelines/2-copy-bulk-images.yaml
----

The feature to bulk-copy several images in the same Pipeline execution is currently affected by https://github.com/tektoncd/catalog/pull/1118[this bug]. To workaround this issue, I've modified the default ClusterTask to fix the issue. Just execute the following:

[source, bash]
----
oc apply -f 10-tasks/2-skopeo-copy.yaml
----


== Running pipelines

.*Copy images from one repo to another*
[source, bash]
----
cat 30-pipelineruns/1-copy-images-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 30-pipelineruns/1-copy-images.yaml

oc create -f 30-pipelineruns/1-copy-images.yaml
----

.*Bulk Copy images from one repo to another*
[source, bash]
----
cat 30-pipelineruns/2-copy-bulk-images-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 30-pipelineruns/2-copy-bulk-images.yaml

oc create -f 30-pipelineruns/2-copy-bulk-images.yaml
----


== Triggers

Triggers capture external events, such as a Git pull request, and process them to extract key pieces of information. Triggers consist of four different CRDs that work together:

* The *TriggerBinding* resource extracts the fields from an event payload and stores them as parameters.
* The *TriggerTemplate* resource acts as a standard for the way resources must be created.
* The *Trigger* resource combines the TriggerBinding and TriggerTemplate resources, and optionally, the interceptors event processor.
* The *EventListener* resource provides an endpoint or an event sink, that listens for incoming HTTP-based events with a JSON payload.


=== Automatic periodic execution of the Pipelines

The following example uses a Kubernetes CronJob to implement a basic cron trigger that runs every minute. This works by using a cron job that emits an HTTP request to the EventListener Service endpoint.


.*Copy images from one repo to another*
[source, bash]
----
cat 40-triggers/1-copy-images-template.yaml | \
PIPELINES_PROJECT=pipelines-test \
envsubst > 40-triggers/1-copy-images.yaml

oc apply -f 40-triggers/1-copy-images.yaml
----



== Secrets for authentication

In many practical use cases, you might need to pull from private Git repositories or might need to push to an external container registry such as Quay.io. In this section, we will summarize how to create the `Secrets` to configure all the credentials.

=== Red Hat Registry

To use the `registry.redhat.io` registry, you have to have a Red Hat login. To consume container images from registry.redhat.io in shared environments such as OpenShift, it is recommended for an administrator to use a Registry Service Account, also referred to as authentication tokens, in place of an individual's Customer Portal credentials.

The management of Service Accounts is available via the https://access.redhat.com/terms-based-registry/#/[Registry Service Account management application].


[source, yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: $SECRET_NAME
data:
  .dockerconfigjson: $DOCKER_CONFIG_FILE_CONTENT
type: kubernetes.io/dockerconfigjson
----

Once you create the file with its contents, you can apply it to the cluster like this:
[source, bash]
----
oc apply -n pipelines-test -f secrets/rh-registry-sa.yaml
oc secrets link -n pipelines-test pipeline rh-registry-sa
----

For more information, check the full https://access.redhat.com/RegistryAuthentication[KCS article].

=== Git repository

To clone a private repository in the pipeline, the `pipeline` Service Account will need to be able to authenticate against the repository. There are basically two main options to get this authentication: Using a username+token (Or a PAT if using GitHub) or using an SSH private key. 

.*Option 1: Create Secret with SSH Private Key*
[source, bash]
----
oc create secret generic git-ssh-key-secret --type=kubernetes.io/ssh-auth --from-file=ssh-privatekey=$LOCATION_PRIVATE_KEY -n pipelines-test
oc annotate secret git-ssh-key-secret tekton.dev/git-0="$GIT_PRIVATE_URL"
oc secrets link pipeline git-ssh-key-secret
----

.*Option 2: Create Secret with GitHub PAT token*
[source, bash]
----
oc create secret generic gh-pat-secret \
    --type=kubernetes.io/basic-auth \
    --from-literal=username=$GITHUB_USERNAME \
    --from-literal=password=$GITHUB_PAT
oc annotate secret gh-pat-secret tekton.dev/git-0="$GIT_PRIVATE_URL"
oc secrets link pipeline gh-pat-secret
----

For more information about the PAT creation and configuration, you can follow the instructions that we have in the following https://rhte2023-argo-rollouts.github.io/redhat-workshop-deployment-strategies/redhat-workshop-deployment-strategies/01-setup.html#_configure_your_github_token[workshop guidelines].


=== Quay Robot Account

Robot accounts are a way to access repositories without requiring a human user account. A robot account has its own credentials, generated by Quay and linked to an Organization. To create a Robot Account and get its credentials, you have to access the Quay web console. For this repository, we are going to use my personal Quay organization, which is located at: https://quay.io/user/alopezme. 

.Quay robot accounts dashboard
image::quay-robot-accounts-dashboard.png["Quay robot accounts dashboard"]

Using an admin account, you can access the organization, go to the Robot Accounts section and click on `Create Robot Account`. After creating the Account, click on it to directly download the Kubernetes secret definition that you have to apply in your namespace.

Once you create the file with its contents, you can apply it to the cluster like this:
[source, bash]
----
oc apply -n pipelines-test -f secrets/quay-alopezme-pull-secret.yaml
oc secrets link -n pipelines-test pipeline quay-alopezme-pull-secret

----

For more information, you can access the https://access.redhat.com/documentation/en-us/red_hat_quay/3.8/html/use_red_hat_quay/use-quay-manage-repo[documentation] of the on-premise installation of Quay.


:sectnums!:

== Annex A: Installing Tekton CLI

To get the most out of Openshift Pipelines, you will need to download and install the `tkn` command line tool. You can download it from the https://tekton.dev/docs/cli/[Tekton documentation] or directly from your Openshift cluster:

.Download tkn cli
image::tkn-cli-download.png["Download tkn cli", width=60%]

== Annex B: Tutorial

If you want a tutorial to learn Openshift Pipelines, I recommend you this https://redhat-scholars.github.io/tekton-tutorial/tekton-tutorial/index.html[tutorial] from Red Hat Scholars.


== Annex C: Default ClusterTasks

The Openshift Pipelines Operator configures several ClusterTasks by default. Here you can find a summary of them for documentation purposes:

[source, text]
----
$ tkn clustertasks list
NAME                        DESCRIPTION              AGE
argocd-task-sync-and-wait   This task syncs (de...   2 days ago
buildah                     Buildah task builds...   2 days ago
git-cli                     This task can be us...   2 days ago
git-clone                   These Tasks are Git...   2 days ago
helm-upgrade-from-repo      These tasks will in...   2 days ago
helm-upgrade-from-source    These tasks will in...   2 days ago
jib-maven                   This Task builds Ja...   2 days ago
kn                          This Task performs ...   2 days ago
kn-apply                    This task deploys a...   2 days ago
kubeconfig-creator          This Task do a simi...   2 days ago
maven                       This Task can be us...   2 days ago
openshift-client            This task runs comm...   2 days ago
pull-request                This Task allows a ...   2 days ago
s2i-dotnet                  s2i-dotnet task fet...   2 days ago
s2i-go                      s2i-go task clones ...   2 days ago
s2i-java                    s2i-java task clone...   2 days ago
s2i-nodejs                  s2i-nodejs task clo...   2 days ago
s2i-perl                    s2i-perl task clone...   2 days ago
s2i-php                     s2i-php task clones...   2 days ago
s2i-python                  s2i-python task clo...   2 days ago
s2i-ruby                    s2i-ruby task clone...   2 days ago
skopeo-copy                 Skopeo is a command...   2 days ago
tkn                         This task performs ...   2 days ago
trigger-jenkins-job         The following task ...   2 days ago
----